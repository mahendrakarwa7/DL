{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937a1abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f75cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "#mnist datasets contains handwritten digits 0 to 9 \n",
    "#10,000 samples testing and 60,000 samples for training\n",
    "data = keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d754bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of data\n",
    "# x -> contains the images  and y-> contains their corresponding integer value\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23edb09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bec93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb3ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all the values of x -> between 0 and 1 divide by 255 (rgb color model)\n",
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125a5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now for model import Sequential model and layers -> Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a138c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)), #defining input image must be of 28*28 dimension (Input Layer)\n",
    "    Dense(150,activation='relu'), #defining the fully connected 150 neurons with activation = relu (Hidden Layer) \n",
    "    Dense(10,activation='softmax') \n",
    "    #defining the fully connected 10 neurons with activation = softmax to classify the output into desired classes (0 to 9) (Output Layer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808d070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First compile the model and then fit the model\n",
    "model.compile(optimizer='SGD',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53aa7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.6386 - accuracy: 0.8388\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3375 - accuracy: 0.9048\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2904 - accuracy: 0.9187\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2607 - accuracy: 0.9275\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2378 - accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1906db3ce20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a819d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2245 - accuracy: 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2245485633611679, 0.9351000189781189]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3193812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "Predicted value:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#classifying the input\n",
    "idx = random.randint(0,len(x_test))\n",
    "plt.imshow(x_test[idx])\n",
    "prediction = model.predict(x_test)\n",
    "print(\"Predicted value: \",np.argmax(prediction[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345798d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
